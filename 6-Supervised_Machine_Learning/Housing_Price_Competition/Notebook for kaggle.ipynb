{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "# from AntiPythonicFunctions import overview, feature_analyzer, feature_analyzer_iterator # another sort of bugfix to do\n",
    "# new stuff for playing around:\n",
    "import sweetviz as sv # Epic feature analysis as .html\n",
    "from dataprep.eda import plot_correlation # Neat correlation plotting\n",
    "# from lazypredict.Supervised import LazyRegressor, LazyClassifier # Uber-modelling\n",
    "# sklearn:\n",
    "from sklearn import set_config\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, OrdinalEncoder, OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer, make_column_selector, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingClassifier, HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, accuracy_score, mean_absolute_percentage_error, mean_squared_log_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# .csv\n",
    "train_df = pd.read_csv(r'train.csv')\n",
    "test_df = pd.read_csv(r'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global setting for sklearn:\n",
    "set_config(transform_output='pandas')\n",
    "# Numpy random state:\n",
    "np.random.seed(1337) # Either be a 1337 Coder or use 42 here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index out of our way:\n",
    "train_df.set_index('Id', inplace=True)\n",
    "test_df.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As well as useless columns concluded from previous EDA(see again at plot_correlation and missing values):\n",
    "train_df.drop(['MSSubClass',\n",
    "               'MoSold',\n",
    "               'Fence',\n",
    "               'Alley',\n",
    "               'PoolArea',\n",
    "               'MiscVal',\n",
    "               'YrSold',\n",
    "               'OverallCond',\n",
    "               'EnclosedPorch',\n",
    "               'LowQualFinSF',\n",
    "               'KitchenAbvGr',\n",
    "               '3SsnPorch',\n",
    "               'ScreenPorch',\n",
    "               'BsmtHalfBath',\n",
    "               'GarageYrBlt',\n",
    "               'MiscFeature',\n",
    "               'BsmtExposure',\n",
    "               'BsmtFinType1',\n",
    "               'BsmtFinType2',\n",
    "               'GarageFinish',\n",
    "               'SaleType',\n",
    "               'SaleCondition'],\n",
    "              axis=1,\n",
    "              inplace=True)\n",
    "test_df.drop(['MSSubClass',\n",
    "               'MoSold',\n",
    "               'Fence',\n",
    "               'Alley',\n",
    "               'PoolArea',\n",
    "               'MiscVal',\n",
    "               'YrSold',\n",
    "               'OverallCond',\n",
    "               'EnclosedPorch',\n",
    "               'LowQualFinSF',\n",
    "               'KitchenAbvGr',\n",
    "               '3SsnPorch',\n",
    "               'ScreenPorch',\n",
    "               'BsmtHalfBath',\n",
    "               'GarageYrBlt',\n",
    "               'MiscFeature',\n",
    "               'BsmtExposure',\n",
    "               'BsmtFinType1',\n",
    "               'BsmtFinType2',\n",
    "               'GarageFinish',\n",
    "               'SaleType',\n",
    "               'SaleCondition'],\n",
    "             axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for further investigations:\n",
    "numeric_train = train_df.select_dtypes(include=['int64', 'float64'])\n",
    "categoric_train = train_df.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(numeric_train.isnull().sum())\n",
    "# plot_correlation(numeric_train, 'SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(categoric_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.hist(bins=50,figsize=(20,20))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To reduce repetitive usage of the \"feature_analyzer\", an iterator to use on all columns.\n",
    "#Loop through all columns except from our targeted one\n",
    "def feature_analyzer_iterator(df, target_variable):\n",
    "    for feature_name in df.columns:\n",
    "        if feature_name != target_variable:\n",
    "            sns.jointplot(data=df, y=target_variable, x=feature_name)\n",
    "            plt.show()\n",
    "\n",
    "            # Description of feature in df.\n",
    "            print(\"\\n****Data DF Info****\")\n",
    "            print(\"Description of {} in df:\".format(feature_name))\n",
    "            print(df[feature_name].describe())\n",
    "\n",
    "            # Value counts of feature in df.\n",
    "            print(\"\\n****Data DF Value Counts****\")\n",
    "            print(\"Value counts of {} in df:\".format(feature_name))\n",
    "            print(df[feature_name].value_counts())\n",
    "\n",
    "            # Mean target_variable value by feature in df.\n",
    "            print(\"\\n****Data DF Mean {} by {}****\".format(target_variable, feature_name))\n",
    "            print(\"Mean {} by {} in df:\".format(target_variable, feature_name))\n",
    "            print(df.groupby(feature_name)[target_variable].mean())\n",
    "\n",
    "            # Skewness of feature in df.\n",
    "            if df[feature_name].dtype!=\"O\":\n",
    "                print(\"\\nSkewness:\",str(skew(df[feature_name])))\n",
    "                \n",
    "# feature_analyzer_iterator(train_df, 'SalePrice') # Use with caution; complete mindfuck, have fun reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now just from notebook:\n",
    "\n",
    "# categories_ordinal = ['ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual','FireplaceQu','GarageQual','GarageCond','PoolQC']\n",
    "\n",
    "# for col in categories_ordinal:\n",
    "#     train_df[col] = train_df[col].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.copy()\n",
    "y = X.pop('SalePrice')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipe = make_pipeline(\n",
    "    KNNImputer(n_neighbors=5))\n",
    "\n",
    "categoric_pipe = make_pipeline(\n",
    "    KNNImputer(n_neighbors=5),\n",
    "    OrdinalEncoder()\n",
    ")    \n",
    "categoric_pipe2 = make_pipeline(\n",
    "    KNNImputer(n_neighbors=5),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\",sparse_output=False)\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "        (numeric_pipe,make_column_selector(dtype_include='number')),\n",
    "        (categoric_pipe, make_column_selector(pattern='ExterQual|ExterCond|BsmtQual|BsmtCond|HeatingQC|KitchenQual|FireplaceQu|GarageQual|GarageCond|PoolQC')),\n",
    "        (categoric_pipe2, make_column_selector(dtype_include='object'))\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    (preprocessor),\n",
    "    (scaler),\n",
    "    (HistGradientBoostingRegressor(random_state=1337))\n",
    ")\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'HistGradientBoostingRegressor__max_depth':range(5,20),\n",
    "    'HistGradientBoostingRegressor__min_samples_leaf':[2,5,20],\n",
    "    #'HistGradientBoostingRegressor__n_estimators':[5,25,100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    verbose=1.1,\n",
    "    scoring='neg_mean_squared_log_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = grid_search.predict(X_test)\n",
    "print(mean_absolute_error(y_test,test_predictions))\n",
    "print(mean_squared_error(y_test,test_predictions))\n",
    "print(mean_squared_log_error(y_test,test_predictions,squared=False))\n",
    "print(mean_absolute_percentage_error(y_test,test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://drive.google.com/file/d/1Z4EAnUyTS3rLKq9ZW7OTCOlPh3fZQ5Mq/view?usp=share_link\"\n",
    "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "data_new = pd.read_csv(path)\n",
    "id_column = data_new.pop('Id')\n",
    "predictions = grid_search.best_estimator_.predict(data_new)\n",
    "results = pd.DataFrame({'Id':id_column,'SalePrice':predictions})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('test3.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea1167cbcaad81cdbbc35255037ba90d13cf758e6bff12ff9eb1557202ecbe5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
